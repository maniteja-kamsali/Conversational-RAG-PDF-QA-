# **Conversational RAG PDF Chatbot** ğŸ“œğŸ’¬

This project is a **Conversational Retrieval-Augmented Generation (RAG) Q&A System** that allows users to **upload PDFs and chat** with their content in real time. It uses **LangChain, Hugging Face embeddings, ChromaDB, and Groq LLM** to retrieve relevant document context and generate concise answers. Built with **Streamlit**, it maintains **chat history** for context-aware responses, providing an interactive experience.

---

## **ğŸš€ Features**
- ğŸ“‚ **Upload multiple PDFs** and extract text content.
- ğŸ¤– **Conversational Q&A** with context-aware responses.
- ğŸ” **Retrieves relevant document sections** for accurate answers.
- ğŸ§  **Uses LangChain, ChromaDB, Hugging Face Embeddings, and Groq LLM**.
- ğŸ’¾ **Maintains chat history per session** using Streamlit's session state.
- ğŸŒ **Interactive Streamlit web interface**.

---

## **ğŸ› ï¸ Installation**

### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/your-username/Conversational-RAG-PDF-QA.git
cd Conversational-RAG-PDF-QA
```

### **2ï¸âƒ£ Create a Virtual Environment**
```bash
conda create --name rag_pdf_chatbot python=3.9 -y
conda activate rag_pdf_chatbot
```

### **3ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

### **4ï¸âƒ£ Set Up API Keys**
- Create a `.env` file and add your **Groq API key** and **Hugging Face API key**:
```env
GROQ_API_KEY=your_groq_api_key
HF_TOKEN=your_huggingface_api_key
```

---

## **ğŸš€ Running the Application**
```bash
streamlit run app.py
```

This will start a local Streamlit server where you can upload PDFs and chat with their content.

---

## **ğŸ“ How It Works**
1ï¸âƒ£ **User uploads PDFs** â†’ Extracts text using `PyPDFLoader`.
2ï¸âƒ£ **Text is split into chunks** â†’ Embeddings are generated using `Hugging Face`.
3ï¸âƒ£ **ChromaDB stores embeddings** â†’ Enables fast document retrieval.
4ï¸âƒ£ **User asks a question** â†’ `contextualize_q_prompt` reformulates it.
5ï¸âƒ£ **Retriever fetches relevant sections** â†’ `qa_prompt` generates an answer.
6ï¸âƒ£ **Chat history is stored** â†’ Ensures context-aware conversations.

---

## **ğŸ“‚ Project Structure**
```bash
ğŸ“‚ Conversational-RAG-PDF-QA/
â”œâ”€â”€ ğŸ“„ app.py               # Main Streamlit application
â”œâ”€â”€ ğŸ“„ requirements.txt     # Dependencies
â”œâ”€â”€ ğŸ“„ .env                 # API keys (not included in repo)
â””â”€â”€ ğŸ“„ README.md            # Project documentation
```

---

## **ğŸ“Œ Future Improvements**
- â˜ï¸ Store chat history in a **database** instead of session state.
- ğŸ“Š Add **visualizations** for retrieved content.
- ğŸ”„ Support **multiple document types** (TXT, DOCX, etc.).

---

## **ğŸ’¡ Contributing**
Feel free to open issues or submit pull requests to improve the project!

---

## **ğŸŒŸ Acknowledgments**
Thanks to **LangChain, ChromaDB, Hugging Face, and Streamlit** for their amazing tools!

---

ğŸš€ **Happy Chatting with PDFs!**

